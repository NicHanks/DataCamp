{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flat Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import this \n",
    "#look up BDFL python glossery | PEP8 / Zen of Python aka 20 aphorisms by \n",
    "# sensei Guido van Rossum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd\n",
    "cars = pd.read_csv('cars.csv', index_col=0)\n",
    "# read and save to a variable:\n",
    "\n",
    "# load chr into digits\n",
    "digits = np.loadtxt(\"mnist_kaggle_some_rows.csv\", delimiter=',') # was digits.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#context manager\n",
    "with open(\"moby_dick.txt\",mode=\"r\") as file: \n",
    "    print(file.read()) # or .readline()\n",
    "# txt file is called flat file\n",
    "#basic text file/records aka table data WITHOUT structured relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "x = [2,3,4]\n",
    "df = pd.DataFrame(x)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loadtxt() and genfromtxt() / type()\n",
    "filename = 'MNIST.txt'\n",
    "data = np.loadtxt(filename, delimiter=',',skiprows=1,usecols=[0,2],dtype=str) #default delimiter is \" \"\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np\n",
    "digits = np.loadtxt(\"mnist_kaggle_some_rows.csv\", delimiter=',') # was digits.csv\n",
    "print(type(digits))\n",
    "# Select and reshape a row\n",
    "im = digits[21, 1:]\n",
    "im_sq = np.reshape(im, (28, 28))\n",
    "# Plot reshaped data (matplotlib.pyplot already loaded as plt)\n",
    "plt.imshow(im_sq, cmap='Greys', interpolation='nearest')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "wd = os.getcwd()\n",
    "print(os.listdir(wd)) # this is printing everything in parent folder\n",
    "print(wd) # this is printing the current command line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pickled files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excel\n",
    "import pickle #this is used for multi tabed excel files/sheets\n",
    "with open('data.pkl', mode=\"rb\") as file: #all this does is open it\n",
    "    d = pickle.load(file) #then this reads it and puts a copy of it into d\n",
    "\n",
    "print(d)\n",
    "print(type(d))\n",
    "#import excel file:\n",
    "file = \"battledeath.xlsx\"\n",
    "\n",
    "# Load spreadsheet: xls\n",
    "xls = pd.ExcelFile(file)\n",
    "\n",
    "# Print sheet names\n",
    "print(xls.sheet_names)\n",
    "df2 = xls.parse(0) # this is to get a single file of the sheet # can be string or index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAS\n",
    "from sas7bdat import SAS7BDAT # Statistical Analysis System / for business analytics and biostatistics\n",
    "\n",
    "with SAS7BDAT('sales.sas7bdat') as file: #this is creating object of that type\n",
    "    df_sas = file.to_data_frame() #this is calling the method object\n",
    "\n",
    "print(df_sas.head())\n",
    "\n",
    "# Plot histogram of DataFrame features (pandas and pyplot already imported)\n",
    "pd.DataFrame.hist(df_sas[['P']])\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stata\n",
    "# \"Statistics\" + \"data\" / Stata: academic social sciences research\n",
    "df = pd.read_stata(\"disarea.dta\") # super simple/easy for stata (pd does all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HDF5\n",
    "\"\"\"HDF5 files\n",
    "• Hierarchical Data Format version 5\n",
    "• Standard for storing large quantities of numerical data\n",
    "• Datasets can be hundreds of gigabytes or terabytes\n",
    "• HDF5 can scale to exabytes\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example\n",
    "import h5py\n",
    "filename = 'H-H1_LOSC_4_V1-815411200-4096.hdf5' #think it's \"disarea.dta\"\n",
    "data = h5py.File(filename, 'p') # 'p' or \"r\" to 'read'\n",
    "print (type(data))\n",
    "for key in data: #could be data[\"meta\"].keys() or data.keys()\n",
    "    print(key) #this prints meta quality strain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#signal processing -> (using h5py)\n",
    "https://campus.datacamp.com/courses/introduction-to-importing-data-in-python/importing-data-from-other-file-types-2?ex=14#:~:text=with%20the%20data-,here,-."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting data strain strain \n",
    "# Get the HDF5 group: group\n",
    "group = data['strain']\n",
    "\n",
    "# Check out keys of group\n",
    "for key in group.keys():\n",
    "    print(key)\n",
    "\n",
    "# Set variable equal to time series data: strain\n",
    "strain = np.array(data['strain']['Strain'])\n",
    "\n",
    "# Set number of time points to sample: num_samples\n",
    "num_samples = 10000\n",
    "\n",
    "# Set time vector\n",
    "time = np.arange(0, 1, 1/num_samples)\n",
    "\n",
    "# Plot data\n",
    "plt.plot(time, strain[:num_samples])\n",
    "plt.xlabel('GPS Time (s)')\n",
    "plt.ylabel('strain')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATRIX LABORATORY\n",
    "#numerical computing invironment | industry standard in engineering and science\n",
    "#.mat\n",
    "\"\"\"SciPy to the rescue!\n",
    "• scipy.io.loadmat - read .mat files\n",
    "• scipy.io.savemat - write .mat files\"\"\"\n",
    "import scipy.io\n",
    "filename = 'workspace.mat'\n",
    "mat = scipy.io.loadmat(filename) #importing as a dict\n",
    "# mat['x'] = key which are variables in mat, values objects assigned to keys\n",
    "# Print the keys of the MATLAB dictionary\n",
    "print(mat.keys())\n",
    "\n",
    "# Print the type of the value corresponding to the key 'CYratioCyt'\n",
    "print(type(mat['CYratioCyt']))\n",
    "\n",
    "# Print the shape of the value corresponding to the key 'CYratioCyt'\n",
    "print(mat['CYratioCyt'].shape)\n",
    "\n",
    "# Subset the array and plot it\n",
    "data = mat['CYratioCyt'][25, 5:]\n",
    "fig = plt.figure()\n",
    "plt.plot(data)\n",
    "plt.xlabel('time (min.)')\n",
    "plt.ylabel('normalized fluorescence (measure of expression)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### relationaldb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relational database\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(\"sqlite:///Chinook.sqlite\") #this is called a connection string\n",
    "table_names = list(engine.table_names())\n",
    "con = engine.connect()\n",
    "rs = con.execut(\"SELECT * FROM Orders\")  #or table_names (i think)\n",
    "df = pd.DataFrame(rs.fetchall())\n",
    "df.columns = rs.keys()\n",
    "con.close()\n",
    "\n",
    "#or\n",
    "engine = create_engine(\"sqlite:///Chinook.sqlite\") \n",
    "with create_engine(\"sqlite:///Chinook.sqlite\") as con: #kinda like a context manager\n",
    "    rs = con.execute(\"FROM * SELECT Orders\")\n",
    "    df = pd.DataFram(rs.fetchall()) #or .fetchmany(size=3)\n",
    "#quering\n",
    "#SELECT * FROM table_names #kinda like 'hello world'\n",
    "#SELECT * FROM Customer WHERE 'Country' = 'Canada' #idk why Country is str\n",
    "#SELECT * FROM Customer WHERE EmployeeId >= 6\n",
    "#SELECT * FROM Customer ORDER BY SupportRepId\n",
    "#SELECT * FROM Employee WHERE EmployeeId >=6 ORDER BY BirthDate\"\n",
    "#SELECT OrderID, CompanyName FROM Orders INNER JOIN Customers on Orders.CustomerID = Customers.CustomerID\n",
    "#SELECT * FROM PlaylistTrack INNER JOIN Track on PlaylistTrack.TrackId = Track.TrackId WHERE Milliseconds < 250000\n",
    "\n",
    "df1 = pd.read_sql_query(\"SELECT * FROM Orders\",engine)\n",
    "\n",
    "print(df.equals(df1)) # Confirm that both methods yield the same result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Advanced querying: exploiting table relationships\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "engine = create_engine ('sqlite:///Northwind.sqlite')\n",
    "df = pd.read_sql_query(\"SELECT OrderID, CompanyName FROM Orders INNER JOIN Customers on Orders. CustomerID = Customers. CustomerID\", engine)\n",
    "print(df.head())\n",
    "df.columns = rs.keys()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
